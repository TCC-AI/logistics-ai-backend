import os
import json
import re
import pandas as pd
import gspread
from flask import Flask, request, jsonify
from google.oauth2.service_account import Credentials
from gspread_formatting import *

app = Flask(__name__)

# --- ğŸ”§ åˆå§‹åŒ–èˆ‡è¨­å®š ---
def get_sh():
    creds_json = os.environ.get('GOOGLE_CREDENTIALS')
    sheet_id = os.environ.get('SHEET_ID')
    
    if not creds_json or not sheet_id:
        raise Exception("ç’°å¢ƒè®Šæ•¸è¨­å®šéŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GOOGLE_CREDENTIALS æˆ– SHEET_ID")

    creds_dict = json.loads(creds_json)
    scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)
    client = gspread.authorize(creds)
    return client.open_by_key(sheet_id)

# --- ğŸ› ï¸ è¼”åŠ©å‡½æ•¸ ---
def parse_route_options(value_str):
    """è§£æ '60%æ—©-åŒ—ä¸€, 40%æ™š-åŒ—ä¸€' æ ¼å¼"""
    if not value_str or pd.isna(value_str):
        return []
    matches = re.findall(r'(\d+)%([^\s,]+)', str(value_str))
    options = []
    for pct, label in matches:
        options.append({'percentage': int(pct), 'label': label})
    # ä¾ç…§ç™¾åˆ†æ¯”ç”±å¤§åˆ°å°æ’åº
    options.sort(key=lambda x: x['percentage'], reverse=True)
    return options

def format_date(val):
    """å°‡å„ç¨®æ—¥æœŸæ ¼å¼çµ±ä¸€è½‰ç‚º YYYY-MM-DD"""
    if pd.isna(val) or val == '': return ''
    try:
        return pd.to_datetime(val).strftime('%Y-%m-%d')
    except:
        return str(val)

# --- ğŸ§¹ æ­¥é©Ÿ 1: æ¸…é™¤æ¡Œé¢ (å°æ‡‰ clearWorkspace/DMode) ---
def step1_clear(sh, mode='A'):
    # å®šç¾©ä¿ç•™åå–® (é›†åˆé‹ç®—æ¯”é™£åˆ—å¿«)
    keep_sheets = {
        'è¨—æ”¶è¨—é‹å›å ±', 'GAIæ¯æ—¥è¨‚å–®åˆ†æ', '5678æœˆè²¨ä¸»æ”¶é€é»åƒç…§', '5678æœˆç­åˆ¥è·¯ç·šåƒç…§', 
        'åƒç…§', 'ç¢³æ’', 'é…é€åœ°å€åƒç…§', 'ä½ç¢³è·¯ç·šè¡¨', 'é€€è²¨è¡¨', 'è¨—æ”¶æ‰˜é‹é»è³‡è¨Š', 
        'è¨—æ”¶æ‰˜é‹é»è³‡è¨Š(ç°¡)', 'æŒ‡å®šæ—¥æœŸ'
    }
    
    # å¦‚æœæ˜¯ Mode Dï¼Œä¿ç•™åŸæœ¬ A/B/C æ¨¡æ…‹ç”¢ç”Ÿçš„è¡¨ï¼Œåªåˆªé™¤ (D) ç›¸é—œ
    # æ ¹æ“šä½ çš„ GAS é‚è¼¯ï¼šD æ¨¡æ…‹åªåˆªé™¤å« (D) çš„è¡¨
    
    worksheets = sh.worksheets()
    deleted_count = 0
    
    for ws in worksheets:
        name = ws.title
        should_delete = False
        
        if mode == 'D':
            # D æ¨¡æ…‹é‚è¼¯ï¼šåªåˆªé™¤åå­—åŒ…å« (D) çš„
            if '(D)' in name or name == 'è¨—æ”¶è¨—é‹å›å ±_ç¯©é¸(D)':
                should_delete = True
        else:
            # A/B/C æ¨¡æ…‹é‚è¼¯ï¼šä¿ç•™åå–®ä»¥å¤–çš„éƒ½åˆªé™¤
            # ä½†ç‚ºäº†å®‰å…¨ï¼Œæˆ‘å€‘é€šå¸¸åªåˆªé™¤ç”Ÿæˆçš„è¡¨ (ç¯©é¸ã€è·¯ç·šè¡¨ã€æ¿æ•¸)
            if name not in keep_sheets:
                if any(k in name for k in ['ç¯©é¸', 'è·¯ç·šè¡¨', 'æ¿æ•¸', '(B)', '(C)', '(D)']):
                    should_delete = True
        
        if should_delete:
            try:
                sh.del_worksheet(ws)
                deleted_count += 1
            except:
                pass
                
    return f"[{mode}æ¨¡æ…‹] å·²æ¸…é™¤ {deleted_count} å€‹å·¥ä½œè¡¨"

# --- ğŸ“… æ­¥é©Ÿ 2: æ—¥æœŸç¯©é¸ (å°æ‡‰ filterDataByDate/DMode) ---
def step2_filter(sh, mode='A'):
    # è¨­å®šå¾Œç¶´
    suffix = ""
    if mode == 'C': suffix = "(C)"
    elif mode == 'D': suffix = "(D)"
    
    target_sheet_name = f'è¨—æ”¶è¨—é‹å›å ±_ç¯©é¸{suffix}'
    
    # 1. è®€å–æ—¥æœŸ
    ws_date = sh.worksheet('æŒ‡å®šæ—¥æœŸ')
    # Dæ¨¡æ…‹è®€ A3, å…¶ä»–è®€ A2
    date_cell = 'A3' if mode == 'D' else 'A2'
    target_date_val = ws_date.acell(date_cell).value
    target_date = format_date(target_date_val)
    
    if not target_date:
        return f"éŒ¯èª¤ï¼šæŒ‡å®šæ—¥æœŸå·¥ä½œè¡¨ ({date_cell}) æœªè¨­å®šæ—¥æœŸ"

    # 2. è®€å–åŸå§‹è³‡æ–™
    ws_source = sh.worksheet('è¨—æ”¶è¨—é‹å›å ±')
    data = ws_source.get_all_values()
    headers = data[0]
    df = pd.DataFrame(data[1:], columns=headers)
    
    # 3. ç¯©é¸
    # å‡è¨­æ—¥æœŸåœ¨ç¬¬ 6 æ¬„ (index 5)
    # å…ˆå°‡è©²æ¬„ä½çµ±ä¸€è½‰å­—ä¸²ä¸¦æ ¼å¼åŒ–ï¼Œå†é€²è¡Œæ¯”å°
    date_col_idx = 5
    
    # é€™è£¡ä½¿ç”¨ apply ä¾†è™•ç†æ—¥æœŸæ ¼å¼ï¼Œç¢ºä¿èˆ‡ target_date æ ¼å¼ä¸€è‡´
    df['fmt_date'] = df.iloc[:, date_col_idx].apply(format_date)
    filtered_df = df[df['fmt_date'] == target_date].drop(columns=['fmt_date'])
    
    if filtered_df.empty:
        return f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ—¥æœŸ {target_date} çš„è³‡æ–™"

    # 4. å¯«å…¥çµæœ
    try:
        ws_target = sh.worksheet(target_sheet_name)
        ws_target.clear()
    except:
        ws_target = sh.add_worksheet(target_sheet_name, rows=1000, cols=len(headers)+10)
    
    # æº–å‚™å¯«å…¥è³‡æ–™
    update_data = [filtered_df.columns.values.tolist()] + filtered_df.values.tolist()
    ws_target.update(update_data)
    
    # è¨­å®šç½®ä¸­ (é¸æ“‡æ€§ï¼Œæœƒç¨å¾®å¢åŠ æ™‚é–“)
    # fmt = CellFormat(horizontalAlignment='CENTER')
    # format_cell_range(ws_target, 'A:Z', fmt)
    
    return f"[{mode}æ¨¡æ…‹] ç¯©é¸å®Œæˆï¼Œå…± {len(filtered_df)} ç­†"

# --- ğŸ›£ï¸ æ­¥é©Ÿ 3: è·¯ç·šæ¯”å° + APP3 (å°æ‡‰ autoRouteMapping + APP3) ---
def step3_mapping(sh, mode='A'):
    suffix = ""
    if mode == 'C': suffix = "(C)"
    elif mode == 'D': suffix = "(D)"
    
    sheet_name = f'è¨—æ”¶è¨—é‹å›å ±_ç¯©é¸{suffix}'
    ws = sh.worksheet(sheet_name)
    
    # è®€å–è³‡æ–™
    df = pd.DataFrame(ws.get_all_records())
    
    # è®€å–åƒç…§è¡¨ (5678æœˆè²¨ä¸»æ”¶é€é»åƒç…§)
    ws_ref = sh.worksheet('5678æœˆè²¨ä¸»æ”¶é€é»åƒç…§')
    df_ref = pd.DataFrame(ws_ref.get_all_records())
    
    # å»ºç«‹æ˜ å°„å­—å…¸
    # å‡è¨­åƒç…§è¡¨æ¬„ä½: è²¨ä¸»(0), æ”¶é€é»(1), Cæ¬„(2), Dæ¬„(3)
    ref_cols = df_ref.columns
    mapping = {}
    for _, row in df_ref.iterrows():
        key = f"{str(row[ref_cols[0]]).strip()}|{str(row[ref_cols[1]]).strip()}"
        mapping[key] = {'C': str(row[ref_cols[2]]), 'D': str(row[ref_cols[3]])}
    
    # æº–å‚™ APP3 çš„æ˜ å°„è¡¨ (åƒç…§)
    ws_code_ref = sh.worksheet('åƒç…§')
    df_code = pd.DataFrame(ws_code_ref.get_all_records())
    code_cols = df_code.columns
    # å»ºç«‹ A->B, C->D, E->F çš„å­—å…¸
    map_ab = dict(zip(df_code[code_cols[0]].astype(str).str.strip(), df_code[code_cols[1]]))
    map_cd = dict(zip(df_code[code_cols[2]].astype(str).str.strip(), df_code[code_cols[3]]))
    map_ef = dict(zip(df_code[code_cols[4]].astype(str).str.strip(), df_code[code_cols[5]]))

    # é–‹å§‹è™•ç†æ¯ä¸€åˆ—
    # å‡è¨­å›å ±è¡¨æ¬„ä½: è²¨ä¸»(4), Hæ¬„(7)
    rep_cols = df.columns
    col_owner = rep_cols[4] # index 4
    col_h = rep_cols[7]     # index 7
    
    x_values = []  # ä¸»è·¯ç·š (ç¬¬24æ¬„)
    ah_values = [] # å‰¯è·¯ç·š (ç¬¬34æ¬„, åƒ… Mode B)
    
    # APP3 çµæœ
    ac_values = [] # å‰5å­—
    aa_values = [] # ç¬¬1å­—
    ab_values = [] # ç¬¬3å­—
    
    for _, row in df.iterrows():
        owner = str(row[col_owner]).strip()
        # è™•ç† H æ¬„ï¼šå»é™¤ (é )
        h_val = str(row[col_h]).strip()
        if h_val.startswith('(é )'): h_val = h_val[3:]
        
        key = f"{owner}|{h_val}"
        
        primary_route = ''
        secondary_route = ''
        
        # --- è·¯ç·šæ¯”å°é‚è¼¯ ---
        if key in mapping:
            ref_data = mapping[key]
            opts_c = parse_route_options(ref_data['C'])
            opts_d = parse_route_options(ref_data['D'])
            all_opts = sorted(opts_c + opts_d, key=lambda x: x['percentage'], reverse=True)
            
            if all_opts:
                primary_route = all_opts[0]['label']
                # Mode B é‚è¼¯ï¼šç¬¬äºŒé¸é … > 40% å¡«å…¥ AH
                if mode == 'B' and len(all_opts) > 1 and all_opts[1]['percentage'] > 40:
                    secondary_route = all_opts[1]['label']
        
        x_values.append(primary_route)
        ah_values.append(secondary_route)
        
        # --- APP3 ä»£ç¢¼æ˜ å°„é‚è¼¯ (é‡å° primary_route / Xæ¬„) ---
        x_str = str(primary_route).strip()
        
        # AC (å‰5å­—) -> Map A->B
        val_ac = map_ab.get(x_str[:5], '') if len(x_str) >= 5 else ''
        ac_values.append(val_ac)
        
        # AA (ç¬¬1å­—) -> Map C->D
        val_aa = map_cd.get(x_str[0], '') if len(x_str) >= 1 else ''
        aa_values.append(val_aa)
        
        # AB (ç¬¬3å­—) -> Map E->F
        val_ab = map_ef.get(x_str[2], '') if len(x_str) >= 3 else ''
        ab_values.append(val_ab)

    # --- æ‰¹æ¬¡å¯«å…¥ ---
    # X æ¬„ (ç¬¬24æ¬„)
    ws.update('X2', [[x] for x in x_values])
    
    # AH æ¬„ (ç¬¬34æ¬„) - åƒ… Mode B å¯«å…¥ï¼Œå…¶ä»–æ¸…ç©º
    if mode == 'B':
        ws.update('AH2', [[x] for x in ah_values])
    else:
        # ç‚ºäº†æ•ˆèƒ½ï¼Œå¦‚æœä¸æ˜¯ Mode Bï¼Œå¯ä»¥é¸æ“‡ä¸æ¸…ç©ºæˆ–å¯«å…¥ç©ºå€¼
        # é€™è£¡ä¾ç…§ GAS é‚è¼¯ï¼šæ¸…ç©º
        empty_col = [[''] for _ in range(len(x_values))]
        ws.update('AH2', empty_col)
        
    # AI æ¬„ (ç¬¬35æ¬„) - GAS é‚è¼¯æ˜¯æ¸…ç©º
    ws.update('AI2', [[''] for _ in range(len(x_values))])
    
    # APP3 å¯«å…¥: AA(27), AB(28), AC(29)
    ws.update('AA2', [[x] for x in aa_values])
    ws.update('AB2', [[x] for x in ab_values])
    ws.update('AC2', [[x] for x in ac_values])
    
    return f"[{mode}æ¨¡æ…‹] è·¯ç·šæ¯”å° & APP3 æ˜ å°„å®Œæˆ"

# --- ğŸ“Š æ­¥é©Ÿ 4: å‰µå»ºå·¥ä½œè¡¨ (å°æ‡‰ createSheetsByRoute) ---
def step4_create(sh, mode='A'):
    suffix = ""
    if mode == 'B': suffix = "(B)"
    elif mode == 'C': suffix = "(C)"
    elif mode == 'D': suffix = "(D)"
    
    # ä¾†æºè¡¨ï¼šMode B ä¾†æºä¹Ÿæ˜¯ç„¡å¾Œç¶´çš„ç¯©é¸è¡¨ï¼Œå…¶ä»–å‰‡æ˜¯å°æ‡‰å¾Œç¶´
    src_name = f'è¨—æ”¶è¨—é‹å›å ±_ç¯©é¸{suffix if mode != "B" else ""}'
    dst_name = f'ç•¶æ—¥å„è·¯ç·šè¡¨{suffix}'
    summary_name = f'å„è·¯ç·šæ¿æ•¸{suffix}'
    
    ws_src = sh.worksheet(src_name)
    df = pd.DataFrame(ws_src.get_all_records())
    
    # æ’é™¤ 'æ˜¶é’' (GAS é‚è¼¯)
    # å‡è¨­ H æ¬„æ˜¯ index 7
    col_h_name = df.columns[7]
    df = df[~df[col_h_name].astype(str).str.contains('æ˜¶é’', na=False)]
    
    # å–å¾— X æ¬„ (index 23) å’Œ AH æ¬„ (index 33)
    col_x = df.columns[23]
    col_ah = df.columns[33]
    
    # å–å¾—æ‰€æœ‰è·¯ç·šåç¨±ä¸¦æ’åº
    routes = set(df[col_x].dropna().unique())
    if mode == 'B':
        routes.update(df[col_ah].dropna().unique())
    
    # ç§»é™¤ç©ºå€¼
    routes = sorted([r for r in routes if r and str(r).strip() != ''])
    
    # æº–å‚™è¼¸å‡ºè³‡æ–™
    final_rows = []
    headers = df.columns.tolist()
    final_rows.append(headers)
    
    # æº–å‚™æ‘˜è¦è³‡æ–™
    summary_rows = [['è·¯ç·šåç¨±', 'æ¿æ•¸ç¸½å’Œ', 'å–è²¨', 'é…é€']]
    
    for route in routes:
        # ç¯©é¸è©²è·¯ç·šè³‡æ–™
        if mode == 'B':
            mask = (df[col_x] == route) | (df[col_ah] == route)
        else:
            mask = (df[col_x] == route)
            
        group = df[mask]
        if group.empty: continue
        
        # --- æ§‹å»ºä¸»è¡¨è³‡æ–™ ---
        # æ¨™é¡Œåˆ—
        title_row = [''] * len(headers)
        title_row[0] = route
        final_rows.append(title_row)
        
        # è³‡æ–™å…§å®¹
        final_rows.extend(group.values.tolist())
        
        # ç¸½å’Œåˆ— (å‡è¨­æ¿æ•¸åœ¨ index 17)
        col_board_idx = 17
        total_boards = pd.to_numeric(group.iloc[:, col_board_idx], errors='coerce').fillna(0).sum()
        sum_row = [''] * len(headers)
        sum_row[col_board_idx] = f"ç¸½å’Œ: {total_boards}"
        final_rows.append(sum_row)
        
        # --- æ§‹å»ºæ‘˜è¦è³‡æ–™ ---
        # çµ±è¨ˆå–è²¨/é…é€ (å‡è¨­æœå‹™é¡å‹åœ¨ index 6, å®¢æˆ¶ååœ¨ index 7)
        col_type_idx = 6
        col_cust_idx = 7
        
        pickup_map = {}
        delivery_map = {}
        
        for _, row in group.iterrows():
            ctype = str(row.iloc[col_type_idx])
            cust = str(row.iloc[col_cust_idx])
            boards = pd.to_numeric(row.iloc[col_board_idx], errors='coerce') or 0
            
            if ctype == 'å–è²¨':
                pickup_map[cust] = pickup_map.get(cust, 0) + boards
            elif ctype == 'é…é€':
                delivery_map[cust] = delivery_map.get(cust, 0) + boards
                
        pickup_str = ", ".join([f"{k} ({v})" for k, v in pickup_map.items()])
        delivery_str = ", ".join([f"{k} ({v})" for k, v in delivery_map.items()])
        
        summary_rows.append([route, total_boards, pickup_str, delivery_str])
        
    # --- å¯«å…¥ä¸»è¡¨ ---
    try:
        ws_dst = sh.worksheet(dst_name)
        ws_dst.clear()
    except:
        ws_dst = sh.add_worksheet(dst_name, rows=len(final_rows)+100, cols=len(headers))
    ws_dst.update(final_rows)
    
    # ç°¡å–®æ ¼å¼åŒ– (æ¨™é¡Œåˆ—ç¶ è‰²)
    # é€™è£¡ç‚ºäº†é€Ÿåº¦å…ˆç•¥éè©³ç´°æ ¼å¼åŒ–ï¼ŒPython å¯«å…¥è³‡æ–™æ‰æ˜¯é‡é»
    
    # --- å¯«å…¥æ‘˜è¦è¡¨ ---
    try:
        ws_sum = sh.worksheet(summary_name)
        ws_sum.clear()
    except:
        ws_sum = sh.add_worksheet(summary_name, rows=len(summary_rows)+20, cols=5)
    ws_sum.update(summary_rows)
    
    return f"[{mode}æ¨¡æ…‹] å·²å»ºç«‹ {dst_name} èˆ‡ {summary_name}"

# --- ğŸš€ API è·¯ç”± ---
@app.route('/', methods=['GET'])
def home():
    return "ç‰©æµ AI ç³»çµ±é‹ä½œä¸­ (Full Logic)"

@app.route('/execute', methods=['POST'])
def execute():
    try:
        data = request.json
        action = data.get('action')
        mode = data.get('mode', 'A')
        
        sh = get_sh()
        msg = ""
        
        if action == 'step1':
            msg = step1_clear(sh, mode)
        elif action == 'step2':
            msg = step2_filter(sh, mode)
        elif action == 'step3':
            msg = step3_mapping(sh, mode)
        elif action == 'step4':
            msg = step4_create(sh, mode)
        elif action == 'all':
            # ä¸²è¯åŸ·è¡Œ
            msgs = []
            if mode == 'A': msgs.append(step1_clear(sh, mode))
            msgs.append(step2_filter(sh, mode))
            msgs.append(step3_mapping(sh, mode))
            msgs.append(step4_create(sh, mode))
            msg = " -> ".join(msgs)
            
        return jsonify({"status": "success", "message": msg})
        
    except Exception as e:
        # å°å‡ºéŒ¯èª¤åˆ° Render Logs æ–¹ä¾¿é™¤éŒ¯
        print(f"Error: {str(e)}")
        return jsonify({"status": "error", "message": str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=10000)
